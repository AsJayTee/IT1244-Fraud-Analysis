{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   region        date  dis    id  catg  target\n",
      "0     101  31/12/1994   60     0    11       0\n",
      "1     107   29/5/2002   69     1    11       0\n",
      "2     301   13/3/1986   62    10    11       0\n",
      "3     105   11/7/1996   69   100    11       0\n",
      "4     303  14/10/2014   62  1000    11       0\n",
      "   id        date  tarif_type  counter_statue  reading_remarque  \\\n",
      "0   0   24/3/2014          11               0                 8   \n",
      "1   0   29/3/2013          11               0                 6   \n",
      "2   0   23/3/2015          11               0                 8   \n",
      "3   0   13/7/2015          11               0                 8   \n",
      "4   0  17/11/2016          11               0                 9   \n",
      "\n",
      "   consommation_level_4  months_number counter_type  counter_coefficient  \\\n",
      "0                     0              4         ELEC                    1   \n",
      "1                     0              4         ELEC                    1   \n",
      "2                     0              4         ELEC                    1   \n",
      "3                     0              4         ELEC                    1   \n",
      "4                     0             12         ELEC                    1   \n",
      "\n",
      "   consommation_level_1  consommation_level_2  consommation_level_3  \n",
      "0                    82                     0                     0  \n",
      "1                  1200                   184                     0  \n",
      "2                   123                     0                     0  \n",
      "3                   102                     0                     0  \n",
      "4                   572                     0                     0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load client and invoice data\n",
    "client_df = pd.read_csv(\"Data/client.csv\")\n",
    "invoice_df = pd.read_csv(\"Data/invoice.csv\")\n",
    "\n",
    "# Preview\n",
    "print(client_df.head())\n",
    "print(invoice_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we parse dates as datetime objects. \n",
    "This ensures date data is processed correctly afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AxoriuM\\AppData\\Local\\Temp\\ipykernel_2316\\413412218.py:2: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  client_df['date'] = pd.to_datetime(client_df['date'])\n",
      "C:\\Users\\AxoriuM\\AppData\\Local\\Temp\\ipykernel_2316\\413412218.py:3: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  invoice_df['date'] = pd.to_datetime(invoice_df['date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   1994-12-31\n",
      "1   2002-05-29\n",
      "2   1986-03-13\n",
      "3   1996-07-11\n",
      "4   2014-10-14\n",
      "Name: date, dtype: datetime64[ns]\n",
      "0   2014-03-24\n",
      "1   2013-03-29\n",
      "2   2015-03-23\n",
      "3   2015-07-13\n",
      "4   2016-11-17\n",
      "Name: date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime\n",
    "client_df['date'] = pd.to_datetime(client_df['date'])\n",
    "invoice_df['date'] = pd.to_datetime(invoice_df['date'])\n",
    "\n",
    "print(client_df['date'].head())\n",
    "print(invoice_df['date'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will work on the client dataset individually, checking for missing data and duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21652 entries, 0 to 21651\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   region  21652 non-null  int64         \n",
      " 1   date    21652 non-null  datetime64[ns]\n",
      " 2   dis     21652 non-null  int64         \n",
      " 3   id      21652 non-null  int64         \n",
      " 4   catg    21652 non-null  int64         \n",
      " 5   target  21652 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(5)\n",
      "memory usage: 1015.1 KB\n",
      "None\n",
      "             region                           date           dis  \\\n",
      "count  21652.000000                          21652  21652.000000   \n",
      "mean     204.851284  2004-04-01 03:40:36.135229952     63.505034   \n",
      "min      101.000000            1977-02-05 00:00:00     60.000000   \n",
      "25%      101.000000            1996-07-11 00:00:00     62.000000   \n",
      "50%      107.000000            2008-03-06 00:00:00     62.000000   \n",
      "75%      307.000000            2013-05-29 00:00:00     69.000000   \n",
      "max      399.000000            2019-06-11 00:00:00     69.000000   \n",
      "std      104.649888                            NaN      3.386026   \n",
      "\n",
      "                  id          catg        target  \n",
      "count   21652.000000  21652.000000  21652.000000  \n",
      "mean   104019.637493     11.372621      0.049695  \n",
      "min         0.000000     11.000000      0.000000  \n",
      "25%    104776.750000     11.000000      0.000000  \n",
      "50%    112726.500000     11.000000      0.000000  \n",
      "75%    120498.250000     11.000000      0.000000  \n",
      "max    128438.000000     51.000000      1.000000  \n",
      "std     31862.072300      3.750705      0.217319  \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check the columns and data types\n",
    "print(client_df.info())\n",
    "\n",
    "# Check for duplicates\n",
    "print(client_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of our client dataset:\n",
    "\n",
    "There is 1 column of date-time data and 5 columns of integer data type, including our target column.There are no missing value at all. There are no duplicate rows of data either.\n",
    "\n",
    "Next, we will correct all data types to ensure our catergorical data are read accordingly, preventing misinterpretation of our categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21652 entries, 0 to 21651\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   region  21652 non-null  category      \n",
      " 1   date    21652 non-null  datetime64[ns]\n",
      " 2   dis     21652 non-null  category      \n",
      " 3   id      21652 non-null  category      \n",
      " 4   catg    21652 non-null  category      \n",
      " 5   target  21652 non-null  category      \n",
      "dtypes: category(5), datetime64[ns](1)\n",
      "memory usage: 982.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical columns to category type \n",
    "columns_to_convert = ['region','dis','id','catg','target']\n",
    "client_df[columns_to_convert] = client_df[columns_to_convert].astype('category')\n",
    "\n",
    "# Checking that our ategorical columns have been converted\n",
    "print(client_df.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
