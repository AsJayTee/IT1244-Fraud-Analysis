{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Started with pandas.\n",
    "Imported invoice dataset.\n",
    "Check first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id        date  tarif_type  counter_statue  reading_remarque  \\\n",
      "0   0   24/3/2014          11               0                 8   \n",
      "1   0   29/3/2013          11               0                 6   \n",
      "2   0   23/3/2015          11               0                 8   \n",
      "3   0   13/7/2015          11               0                 8   \n",
      "4   0  17/11/2016          11               0                 9   \n",
      "\n",
      "   consommation_level_4  months_number counter_type  counter_coefficient  \\\n",
      "0                     0              4         ELEC                    1   \n",
      "1                     0              4         ELEC                    1   \n",
      "2                     0              4         ELEC                    1   \n",
      "3                     0              4         ELEC                    1   \n",
      "4                     0             12         ELEC                    1   \n",
      "\n",
      "   consommation_level_1  consommation_level_2  consommation_level_3  \n",
      "0                    82                     0                     0  \n",
      "1                  1200                   184                     0  \n",
      "2                   123                     0                     0  \n",
      "3                   102                     0                     0  \n",
      "4                   572                     0                     0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load invoice data\n",
    "invoice_df = pd.read_csv(\"Data/invoice.csv\")\n",
    "\n",
    "# Preview\n",
    "print(invoice_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for empty data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                      0\n",
      "date                    0\n",
      "tarif_type              0\n",
      "counter_statue          0\n",
      "reading_remarque        0\n",
      "consommation_level_4    0\n",
      "months_number           0\n",
      "counter_type            0\n",
      "counter_coefficient     0\n",
      "consommation_level_1    0\n",
      "consommation_level_2    0\n",
      "consommation_level_3    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(invoice_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No empty data detected. \n",
    "Now, we parse dates as datetime objects. \n",
    "This ensures date data is processed correctly afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2014-03-24\n",
      "1   2013-03-29\n",
      "2   2015-03-23\n",
      "3   2015-07-13\n",
      "4   2016-11-17\n",
      "Name: date, dtype: datetime64[ns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/f9l8cr254_905tmd749bc8sw0000gn/T/ipykernel_5066/1043635998.py:2: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  invoice_df['date'] = pd.to_datetime(invoice_df['date'])\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime\n",
    "invoice_df['date'] = pd.to_datetime(invoice_df['date'])\n",
    "\n",
    "print(invoice_df['date'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We intend to classify clients, so we tried to summarise invoice data by client. For each client, we computed rough statistics such as the mean , date and sum for our focus on consumption levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  consommation_level_1_sum  consommation_level_1_mean  \\\n",
      "0    0                     12334                 352.400000   \n",
      "1    1                     20629                 557.540541   \n",
      "2   10                     14375                 798.611111   \n",
      "3   12                      5724                 357.750000   \n",
      "4  100                        24                   1.200000   \n",
      "\n",
      "   consommation_level_1_max  consommation_level_1_std  \\\n",
      "0                      1200                310.343472   \n",
      "1                      1207                197.935960   \n",
      "2                      2400                513.841374   \n",
      "3                       925                232.908995   \n",
      "4                        15                  3.607011   \n",
      "\n",
      "   consommation_level_2_sum  consommation_level_2_mean  \\\n",
      "0                       370                  10.571429   \n",
      "1                         0                   0.000000   \n",
      "2                       682                  37.888889   \n",
      "3                      1740                 108.750000   \n",
      "4                         0                   0.000000   \n",
      "\n",
      "   consommation_level_2_max  consommation_level_2_std  \\\n",
      "0                       186                 43.568935   \n",
      "1                         0                  0.000000   \n",
      "2                       682                160.748942   \n",
      "3                       422                150.329194   \n",
      "4                         0                  0.000000   \n",
      "\n",
      "   consommation_level_3_sum  ...  consommation_level_3_max  \\\n",
      "0                         0  ...                         0   \n",
      "1                         0  ...                         0   \n",
      "2                         0  ...                         0   \n",
      "3                       266  ...                       266   \n",
      "4                         0  ...                         0   \n",
      "\n",
      "   consommation_level_3_std  consommation_level_4_sum  \\\n",
      "0                       0.0                         0   \n",
      "1                       0.0                         0   \n",
      "2                       0.0                         0   \n",
      "3                      66.5                         0   \n",
      "4                       0.0                         0   \n",
      "\n",
      "   consommation_level_4_mean  consommation_level_4_max  \\\n",
      "0                        0.0                         0   \n",
      "1                        0.0                         0   \n",
      "2                        0.0                         0   \n",
      "3                        0.0                         0   \n",
      "4                        0.0                         0   \n",
      "\n",
      "   consommation_level_4_std   date_min   date_max counter_statue_count  \\\n",
      "0                       0.0 2005-10-17 2019-03-19                   35   \n",
      "1                       0.0 2005-10-19 2019-04-02                   37   \n",
      "2                       0.0 2005-11-10 2019-05-02                   18   \n",
      "3                       0.0 2011-10-08 2019-08-16                   16   \n",
      "4                       0.0 2005-06-10 2012-09-25                   20   \n",
      "\n",
      "   elapsed_time  \n",
      "0          4901  \n",
      "1          4913  \n",
      "2          4921  \n",
      "3          2869  \n",
      "4          2664  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Aggregating invoice data by client 'id'\n",
    "consumption_stats = invoice_df.groupby('id').agg({\n",
    "    'consommation_level_1': ['sum', 'mean', 'max', 'std'],\n",
    "    'consommation_level_2': ['sum', 'mean', 'max', 'std'],\n",
    "    'consommation_level_3': ['sum', 'mean', 'max', 'std'],\n",
    "    'consommation_level_4': ['sum', 'mean', 'max', 'std'],\n",
    "    'date': ['min', 'max'],     # Add earliest and latest invoice date\n",
    "    'counter_statue': 'count',  # How many invoices per client\n",
    "}).reset_index()\n",
    "\n",
    "consumption_stats.columns = ['_'.join(col).strip() if col[1] else col[0] for col in consumption_stats.columns.values]\n",
    "\n",
    "consumption_stats['elapsed_time'] = (consumption_stats['date_max'] - consumption_stats['date_min']).dt.days\n",
    "\n",
    "# Preview the data\n",
    "print(consumption_stats.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we highlight possible anomalous clients. Could be fraud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated invoice data with anomaly flag based on IQR:\n",
      "   id       date  tarif_type  counter_statue  reading_remarque  \\\n",
      "0   0 2014-03-24          11               0                 8   \n",
      "1   0 2013-03-29          11               0                 6   \n",
      "2   0 2015-03-23          11               0                 8   \n",
      "3   0 2015-07-13          11               0                 8   \n",
      "4   0 2016-11-17          11               0                 9   \n",
      "\n",
      "   consommation_level_4  months_number counter_type  counter_coefficient  \\\n",
      "0                     0              4         ELEC                    1   \n",
      "1                     0              4         ELEC                    1   \n",
      "2                     0              4         ELEC                    1   \n",
      "3                     0              4         ELEC                    1   \n",
      "4                     0             12         ELEC                    1   \n",
      "\n",
      "   consommation_level_1  consommation_level_2  consommation_level_3  \\\n",
      "0                    82                     0                     0   \n",
      "1                  1200                   184                     0   \n",
      "2                   123                     0                     0   \n",
      "3                   102                     0                     0   \n",
      "4                   572                     0                     0   \n",
      "\n",
      "   anomaly_flag  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n"
     ]
    }
   ],
   "source": [
    "# Calculate IQR for consumption_level_1\n",
    "Q1 = consumption_stats['consommation_level_1_sum'].quantile(0.25)\n",
    "Q3 = consumption_stats['consommation_level_1_sum'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define anomaly boundaries using IQR\n",
    "lower_bound = Q1 - 1.5 * IQR  # Lower bound for anomalies\n",
    "upper_bound = Q3 + 1.5 * IQR  # Upper bound for anomalies\n",
    "\n",
    "# Flagging anomalies based on IQR for consumption level 1\n",
    "consumption_stats['anomaly_flag'] = np.where(\n",
    "    (consumption_stats['consommation_level_1_sum'] < lower_bound) |  # Below the lower bound (too low)\n",
    "    (consumption_stats['consommation_level_1_sum'] > upper_bound),   # Above the upper bound (too high)\n",
    "    1,  # Mark as anomaly\n",
    "    0   # Mark as normal\n",
    ")\n",
    "\n",
    "# Merge the anomaly flags back to the original invoice data based on 'id'\n",
    "invoice_with_anomalies = pd.merge(invoice_df, consumption_stats[['id', 'anomaly_flag']], on='id', how='left')\n",
    "\n",
    "# Save the updated dataset (with anomalies) back to the original invoice.csv file\n",
    "invoice_with_anomalies.to_csv(\"Data/invoice.csv\", index=False)\n",
    "\n",
    "# Preview the updated dataset\n",
    "print(\"Updated invoice data with anomaly flag based on IQR:\")\n",
    "print(invoice_with_anomalies.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
