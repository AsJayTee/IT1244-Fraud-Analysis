{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"Data/{filename}.csv\" # TO UPDATE after feature engineering is complete\n",
    "\n",
    "# Column names from feature engineered dataset\n",
    "response_col_name = \"\" # Response col\n",
    "cat_col_names = [] # Categorical col \n",
    "num_col_names = [] # Numerical col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataframe(\n",
    "        df : pd.DataFrame, \n",
    "        response_col_name : str,\n",
    "        cat_col_names : list[str] = [], \n",
    "        num_col_names : list[str] = [],\n",
    "        scale : bool = True,\n",
    "        OHE : bool = True\n",
    "        ) -> pd.DataFrame:\n",
    "    '''For scaling and one-hot encoding dataframe'''\n",
    "    \n",
    "    y = df[response_col_name].values # Response column\n",
    "    X_num = df[num_col_names].values # Numerical columns\n",
    "    X_cat = df[cat_col_names].values # Categorical columns\n",
    "\n",
    "    if scale:\n",
    "        # Scale numerical features\n",
    "        scaler = StandardScaler()\n",
    "        X_num = scaler.fit_transform(X_num)\n",
    "\n",
    "    if OHE:\n",
    "        # One-hot encode categorical features\n",
    "        encoder = OneHotEncoder(sparse = False, drop = 'first')  # drop = 'first' to avoid dummy variable trap\n",
    "        X_cat = encoder.fit_transform(X_cat)\n",
    "    \n",
    "    # Combine the scaled numerical and encoded categorical features\n",
    "    X_preprocessed = pd.DataFrame(\n",
    "        data = np.hstack((X_num, X_cat)),  # Horizontal stack to combine arrays\n",
    "        columns = num_col_names + list(encoder.get_feature_names_out(cat_col_names))\n",
    "    )\n",
    "\n",
    "    # Create a new DataFrame including the response variable\n",
    "    preprocessed_df = pd.DataFrame(X_preprocessed, columns = X_preprocessed.columns)\n",
    "    preprocessed_df[response_col_name] = y\n",
    "\n",
    "    return preprocessed_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def principal_component_analysis(\n",
    "        df : pd.DataFrame, \n",
    "        response_col_name : str,\n",
    "        cat_col_names : list[str] = [], \n",
    "        num_col_names : list[str] = [],\n",
    "        var : float = 0.95, logs : bool = False\n",
    "        ) -> pd.DataFrame:\n",
    "\n",
    "    y = df[response_col_name].values # Response column\n",
    "    X_num = df[num_col_names].values # Numerical columns\n",
    "    X_cat = df[cat_col_names].values # Categorical columns\n",
    "\n",
    "    pca = PCA(n_components = var) # Keep 'var' proportion of the variance : default 95%\n",
    "    X_pca = pca.fit_transform(X_num) \n",
    "\n",
    "    pca_columns = [f'PC{i+1}' for i in range(X_pca.shape[1])]\n",
    "    df_pca = pd.DataFrame(X_pca, columns = pca_columns)\n",
    "\n",
    "    df_modified = pd.concat(\n",
    "        [\n",
    "            df_pca, \n",
    "            pd.DataFrame(X_cat, columns = cat_col_names), \n",
    "            pd.Series(y, name = response_col_name)\n",
    "        ], \n",
    "        axis = 1)\n",
    "    \n",
    "    if logs:\n",
    "        print(f\"Number of components selected: {pca.n_components_}\")\n",
    "        print(\"Explained variance ratio for each component:\", pca.explained_variance_ratio_)\n",
    "        print(\"Cumulative explained variance:\", pca.explained_variance_ratio_.cumsum())\n",
    "        print(\"Final DataFrame with PCA applied to numeric columns:\")\n",
    "        print(df_modified.head())\n",
    "\n",
    "    return df_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
