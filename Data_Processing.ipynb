{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Importing functions\n",
    "\n",
    "def import_client(filepath : str = \"Data/client.csv\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to import client dataset.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "def import_invoice(filepath : str = \"Data/invoice.csv\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to import invoice dataset.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preprocessing functions\n",
    "\n",
    "def convert_to_dates(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts date column to datetime object.\n",
    "    *Column name 'date' is fixed for both datasets.\n",
    "    \"\"\"\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    return df\n",
    "\n",
    "def drop_duplicates(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prints the result of a duplicate check.\n",
    "    Drops duplicates if they exist.\n",
    "    \"\"\"\n",
    "    if df.duplicated().any(): # Duplicates check\n",
    "        print(\"Duplicates found! Cleaning them up...\")\n",
    "        df = df.drop_duplicates() # Drops duplicates\n",
    "        df = df.reset_index(drop = True) # Resets indexes\n",
    "    else:\n",
    "        print(\"No duplicates found!\")\n",
    "    return df\n",
    "\n",
    "def convert_to_categorical(\n",
    "        df : pd.DataFrame,\n",
    "        cols : list[str]\n",
    "        ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts list of column names to categorical datatype.\n",
    "    \"\"\"\n",
    "    df[cols] = df[cols].astype('category')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Feature Engineering functions\n",
    "\n",
    "def aggregate_invoice(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate the invoice dataframe by id and generate features.\n",
    "    Calculates sum, mean, max, and std for each consommation_level\n",
    "    and counts number of invoices under each id.\n",
    "    \"\"\"\n",
    "    df = df.groupby('id').agg({ # Aggregate by id\n",
    "        # Calculate sum, mean, max, and std for each consm_level\n",
    "        'consommation_level_1': ['sum', 'mean', 'max', 'std'],\n",
    "        'consommation_level_2': ['sum', 'mean', 'max', 'std'],\n",
    "        'consommation_level_3': ['sum', 'mean', 'max', 'std'],\n",
    "        'consommation_level_4': ['sum', 'mean', 'max', 'std'],\n",
    "        'counter_statue': 'count', # Count number of invoices\n",
    "    }).reset_index()\n",
    "    df.columns = [\n",
    "        # Join by _ if more than 2 parts to the column name exists\n",
    "        '_'.join(col).strip() if col[1] \n",
    "        else col[0] # Else use original name\n",
    "        for col in df.columns.values # For each column name value\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "def manual_fix_names(\n",
    "        df : pd.DataFrame,\n",
    "        new_col_names : list[str]\n",
    "        ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Manually sets the column names of a dataframe.\n",
    "    \"\"\"\n",
    "    df.columns = new_col_names\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Joining functions\n",
    "\n",
    "def merge(\n",
    "        client_df : pd.DataFrame,\n",
    "        invoice_df : pd.DataFrame,\n",
    "        merge_by : str = \"id\"\n",
    "        ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges two dataframes.\n",
    "    Merges on 'id' column by default (for client and invoice).\n",
    "    \"\"\"\n",
    "    merged_df = pd.merge(\n",
    "        client_df, invoice_df, on = merge_by)\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define main workflow\n",
    "\n",
    "def main(): \n",
    "    client_df = import_client()\n",
    "    invoice_df = import_invoice()\n",
    "    client_df = convert_to_dates(client_df) # Convert date cols\n",
    "    invoice_df = convert_to_dates(invoice_df)\n",
    "    client_df = drop_duplicates(client_df) # Drop duplicates rows\n",
    "    invoice_df = drop_duplicates(invoice_df)\n",
    "    client_df = convert_to_categorical( # Convert categorical cols\n",
    "        client_df, cols = ['region', 'dis', 'id', 'catg', 'target']\n",
    "        )\n",
    "    invoice_df = aggregate_invoice(invoice_df) # Aggregate invoices\n",
    "    invoice_df = manual_fix_names( # Fix column names manually\n",
    "        invoice_df, \n",
    "        new_col_names = [\n",
    "            'id', \n",
    "            'cons_level_1_sum', 'cons_level_1_mean', \n",
    "            'cons_level_1_max', 'cons_level_1_std',\n",
    "            'cons_level_2_sum', 'cons_level_2_mean', \n",
    "            'cons_level_2_max', 'cons_level_2_std',\n",
    "            'cons_level_3_sum', 'cons_level_3_mean', \n",
    "            'cons_level_3_max', 'cons_level_3_std',\n",
    "            'cons_level_4_sum', 'cons_level_4_mean', \n",
    "            'cons_level_4_max', 'cons_level_4_std',\n",
    "            'num_invoices'\n",
    "            ]\n",
    "        )\n",
    "    merged_df = merge(client_df = client_df, invoice_df = invoice_df)\n",
    "    print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siah Jin Thau\\AppData\\Local\\Temp\\ipykernel_4076\\3519587774.py:8: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['date'] = pd.to_datetime(df['date'])\n",
      "C:\\Users\\Siah Jin Thau\\AppData\\Local\\Temp\\ipykernel_4076\\3519587774.py:8: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['date'] = pd.to_datetime(df['date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found!\n",
      "Duplicates found! Cleaning them up...\n",
      "  region       date dis    id catg target  cons_level_1_sum  \\\n",
      "0    101 1994-12-31  60     0   11      0             12334   \n",
      "1    107 2002-05-29  69     1   11      0             20629   \n",
      "2    301 1986-03-13  62    10   11      0             14375   \n",
      "3    105 1996-07-11  69   100   11      0                24   \n",
      "4    303 2014-10-14  62  1000   11      0              9292   \n",
      "\n",
      "   cons_level_1_mean  cons_level_1_max  cons_level_1_std  ...  \\\n",
      "0         352.400000              1200        310.343472  ...   \n",
      "1         557.540541              1207        197.935960  ...   \n",
      "2         798.611111              2400        513.841374  ...   \n",
      "3           1.200000                15          3.607011  ...   \n",
      "4         663.714286               800        224.831365  ...   \n",
      "\n",
      "   cons_level_2_std  cons_level_3_sum  cons_level_3_mean  cons_level_3_max  \\\n",
      "0         43.568935                 0           0.000000                 0   \n",
      "1          0.000000                 0           0.000000                 0   \n",
      "2        160.748942                 0           0.000000                 0   \n",
      "3          0.000000                 0           0.000000                 0   \n",
      "4        167.155320              1643         117.357143               800   \n",
      "\n",
      "   cons_level_3_std  cons_level_4_sum  cons_level_4_mean  cons_level_4_max  \\\n",
      "0          0.000000                 0           0.000000                 0   \n",
      "1          0.000000                 0           0.000000                 0   \n",
      "2          0.000000                 0           0.000000                 0   \n",
      "3          0.000000                 0           0.000000                 0   \n",
      "4        289.433294               514          36.714286               382   \n",
      "\n",
      "   cons_level_4_std  num_invoices  \n",
      "0          0.000000            35  \n",
      "1          0.000000            37  \n",
      "2          0.000000            18  \n",
      "3          0.000000            20  \n",
      "4        105.421081            14  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "## Run to execute main workflow\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
